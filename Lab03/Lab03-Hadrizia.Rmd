---
title: "Lab03"
author: "Hadrizia Santos"
date: "26 de fevereiro de 2018"
output: html_document
---

**Carregando bibliotecas necessárias**

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(caret)
library(ggplot2)
library(lattice)
library(dplyr)
library(rpart)
library(rpart.plot) 
library(ROSE)
```

*Carregando, separando em treino e teste e pre processando os dados*

```{r}
## carregando os dados de treino
input <- read.csv("~/Downloads/LabsAD2/Lab03/train.csv", encoding = "latin1")

## pre-processando os dados (removendo variáveis irrelevantes)
input <- input %>% select(-ID, -nome, -numero_cadidato, -idade, -estado_civil, -grau, -setor_economico_despesa, -setor_economico_receita)

# carregando os dados de teste
input_teste <- read.csv("~/Downloads/LabsAD2/Lab03/test.csv", encoding = "latin1")

# para uso da submissao no Kaggle
ID <-input_teste %>% select(ID)
input_teste <- input_teste %>% select(-ID, -nome, -numero_cadidato, -idade, -estado_civil, -grau,
                                      -setor_economico_despesa, -setor_economico_receita)

## criando partição de 75% em treino e 25% em teste
dataPartition <- createDataPartition(y = input$situacao_final, p=0.75, list=FALSE)

## Setando a seed para fazer a partição reproduzível
set.seed(9560)

## separando o dataframe em treino e teste
train_data <- input[dataPartition, ]
test_data <- input[-dataPartition, ]
```

**1. Há desbalanceamento das classes (isto é, uma classe tem muito mais instâncias que outra)? Em que proporção? Quais efeitos colaterais o desbalanceamento de classes pode causar no classificador?**

Para responder a esta pergunta, precisamos contabilizar as instâncias das classes de situacao_final para verificar se há desbalanceamento entre elas.

```{r}
cont_nao_eleito <- input %>% select(situacao_final) %>% filter(situacao_final == 'nao_eleito') %>% nrow()
cont_eleito <- input %>% select(situacao_final) %>% filter(situacao_final == 'eleito') %>% nrow()

df = data.frame(situacao = c("eleito", "não eleito"), count = c(cont_eleito, cont_nao_eleito)) 

ggplot(df, aes(x="", y=count, fill=situacao))+
geom_bar(width = 1, stat = "identity") +
   coord_polar("y", start=0)
```

Como se pode observar no gráfico acima, há um grande desbalanceamento das classes de situacao_final. o número de candidatos não eleitos é quase 10 vezes maior do que o número de candidatos eleitos. Este é um problema que possui como principal efeito colateral a redução da acurácia dos modelos, uma vez que o classificador vai tender para a classe majoritária (neste casso, a não eleição dos votos).

Para contornar o problema do desbalanceamento existem algumas formas, destacando-se undersampling, que consiste em remover algumas instâncias do dataset cuja classe é a majoritária e oversampling, que cria instâncias da classe minoritária. 

Abaixo tem-se os dois métodos citados acima, além do método ROSE, e lista o número de instâncias de cada método utilizado. 

```{r}

train_data <- train_data %>% select(-recursos_de_outros_candidatos.comites, -recursos_de_partidos, -recursos_de_pessoas_fÃ.sicas, -recursos_de_pessoas_juridicas, -recursos_proprios)

#input_teste$isDeputado <- ifelse(input_teste$descricao_ocupacao == "DEPUTADO", 1, 0)
#input_teste <- input_teste %>% select(total_receita, despesa_max_campanha, isDeputado)

rose_train <- ROSE(situacao_final ~ ., data  = train_data)$data                         
table(rose_train$situacao_final) 

up_train <- upSample(x = train_data[,],
                     y = train_data$situacao_final)  

up_train <- up_train %>% select(-Class)
table(up_train$situacao_final) 

down_train <- downSample(x = train_data[, -ncol(train_data)],
                         y = train_data$situacao_final)
down_train <- down_train %>% select(-Class)
table(down_train$situacao_final)  
```

O método escolhido será o ROSE, que tanto cria instâncias da classe minoritária quanto diminui instâncias da classe majoritária.

**2. Treine: um modelo de regressão logística, uma árvore de decisão e um modelo de adaboost. Tune esses modelos usando validação cruzada e controle overfitting se necessário, considerando as particularidades de cada modelo.**

```{r}
# usando validação cruzada 10-fold com 5 repetições
fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 5,
                           classProbs = TRUE)
```

Regressão Logística

```{r warning=FALSE}
reg_logistica <- glm(formula=situacao_final~., data = rose_train, family=binomial)
```

Árvore de decisão

```{r}
arvore <- train(
    x = rose_train[, names(rose_train) != "situacao_final"],
    y = rose_train$situacao_final,
    method = "rpart",
    trControl = fitControl,
    control = rpart.control(cp = 0.4))
```

Adaboost

```{r}
adaboost <- train(x = rose_train[, names(rose_train) != "situacao_final"],
                y = rose_train$situacao_final,
                method = "adaboost",
                trControl = fitControl)
```

**3. Reporte acurácia, precision, recall e f-measure no treino e validação. Como você avalia os resultados? Justifique sua resposta.**

A análise será feita no modelo adaboost.

```{r}
# realizando predição 
test_data$prediction <- predict(adaboost, test_data)

# para uso da submissao no Kaggle
#newCSV <- ID
#newCSV$prediction <- prediction
#write.csv(newCSV, "sample_submission.csv", row.names=FALSE)

# vezes que o modelo acertou na predição de que o candidato seria eleito
TP <- test_data %>% filter(situacao_final == "eleito", prediction == "eleito") %>% nrow()

# vezes que o modelo acertou na predição de que o candidato seria nao_eleito
TN <- test_data %>% filter(situacao_final == "nao_eleito" , prediction == "nao_eleito" ) %>% nrow()

# vezes que o modelo errou na predição de que o candidato seria nao_eleito
FP <- test_data %>% filter(situacao_final == "nao_eleito" , prediction == "eleito") %>% nrow() 

# vezes que o modelo errou na predição de que o candidato seria eleito
FN <- test_data %>% filter(situacao_final == "eleito", prediction == "nao_eleito" ) %>% nrow()

# proporção de observações corretamente classificadas
accuracy <- (TP + TN)/(TP + TN + FP + FN) 

# quantas das observaçoes preditas como positivas são realmente positivas
precision <- TP / (TP + FP)

# quantas das observaçoes positivas foram corretamente classificadas
recall <- TP / (TP + FN)

# média harmônica da precisão e recall
f_measure <- 2 * (precision * recall) / (precision + recall)

f_measure
accuracy
precision
recall

confusionMatrix(test_data$prediction, test_data$situacao_final)
varImp(adaboost)
```

No treino, o modelo teve acurácia igual a 0.9878164; na validação, esse valor diminuiu para 0.946757.O resultado foi satisfatório pois o modelo conseguiu predizer corretamente o resultado da eleição na maioria dos casos. Possui nível de falso-positivo consideravelmente elevado, que acarretou na diminuição da precisão do modelo; e baixo nível de falso negativo, que aumenta o recall. O f-measure, que é medido calculando a média harmônica entre precisão e recall, ter valor próximo a 1 é um bom indicador que o modelo é um bom preditor.

**4. Interprete as saídas dos modelos. Quais atributos parecem ser mais importantes de acordo com cada modelo? Crie pelo menos um novo atributo que não está nos dados originais e estude o impacto desse atributo.**

Vamos analisar o impacto, em cada modelo, de criar um novo atributo chamado isDeputado, que possui valor 1 caso o candidato já seja deputado e 0, caso contrário.

```{r}
rose_train$isDeputado <- ifelse(rose_train$descricao_ocupacao == "DEPUTADO", 1, 0)
test_data$isDeputado <- ifelse(test_data$descricao_ocupacao == "DEPUTADO", 1, 0)
```

Regressão Logística

```{r}
# antes do atributo 
summary(reg_logistica)
```

```{r warning=FALSE}
# re-treinando o modelo
reg_logistica <- glm(formula=situacao_final~., data = rose_train, family=binomial)
```

```{r}
# depois do atributo
summary(reg_logistica)
```

No modelo de Regressão Logística, alguns atributos de descricao_ocupacao, quantidade_fornecedores, total_despesa, media_despesa, sexo, recursos_de_pessoas_físicas, recursos_de_pessoas_juridicas, quantidade_doacoes, quantidade_doadores, total_receita, media_receita uf e partido parecem ser bem importantes. A inserção do atributo isDeputado não teve muita relevância para o modelo de regressão logística e o modelo teve acurácia reduzida no treino.

Árvore de Decisão

```{r}
# antes do atributo 
arvore
varImp(arvore)
```

```{r}
# re-treinando o modelo
arvore <- train(
    x = rose_train[, names(rose_train) != "situacao_final"],
    y = rose_train$situacao_final,
    method = "rpart",
    trControl = fitControl,
    control = rpart.control(cp = 0.4))
```

```{r}
# depois do atributo
arvore
varImp(arvore)
```

No modelo de Árvore de Decisão, os atributos total_despesa, recursos_de_pessoas_juridicas, total_receita, recursos_de_partidos e quantidade_doacoes parecem ser mais importantes. A inserção da variável isDeputado não aumentou a acurácia significantemente.

Adaboost

```{r}
# antes do atributo Adaboost.M1    0.9878164  0.9756358
adaboost
varImp(adaboost)
```

```{r}
# re-treinando o modelo
adaboost <- train(x = rose_train[, names(rose_train) != "situacao_final"],
                y = rose_train$situacao_final,
                method = "adaboost",
                trControl = fitControl)
```

```{r}
# depois do atributo
adaboost
varImp(adaboost)
```

No modelo Adaboost, total_receita, total_despesa, quantidade_doacoes, media_receita, recursos_de_pessoas_físicas, quantidade_doadores, quantidade_despesas, recursos_de_pessoas_juridicas, recursos_de_partidos, quantidade_fornecedores e media_despesa parecem ser as mais importantes. A inserção do atributo diminuiu a acurácia do modelo no treino.