---
title: "Lab02 - Predição de Votação de Deputados"
author: "Hadrizia Santos"
date: "11 de dezembro de 2017"
output: html_document
---

**Carregando bibliotecas necessárias**

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
library(readr)
library(caret)
library(dplyr)
```

**Carregando os dados e removendo informações pouco relevantes, como nome, cargo, número e sequencial do candidato**

```{r}
input <- read.csv("~/Downloads/eleicoes2014.csv", encoding = "latin1")
  input <- input %>% select(-cargo)

## Setando os valores NA para zero
input[is.na(input)] <- 0

## gerando partição de 75% dos dados
smp_size <- floor(0.75 * nrow(input))

## Setando a seed para fazer a partição reproduzível
set.seed(123)

## Particionando o dataset em dois: treino (75%) e teste (25%)
train_ind <- sample(seq_len(nrow(input)), size = smp_size)
train <- input[train_ind, ]
test <- input[-train_ind, ]

polyexp = function(df){
  df.polyexp = df
  colnames = colnames(df)
  for (i in 1:ncol(df)){
    for (j in i:ncol(df)){
      colnames = c(colnames, paste0(names(df)[i],'.',names(df)[j]))
      df.polyexp = cbind(df.polyexp, df[,i]*df[,j])
    }
  }
  names(df.polyexp) = colnames
  return(df.polyexp)
}

polyexp(train)

```

**1. Usando todas as variáveis disponíveis, tune (usando validação cruzada): (i) um modelo de regressão Ridge, (ii) um modelo de regressão Lasso e (iii) um modelo KNN. Para os modelos de regressão linear, o parâmetro a ser tunado é o lambda (penalização dos coeficientes) e o KNN o número de vizinhos.**
    ''
Usando validação cruzada 

```{r}
fitControl <- trainControl(method = "repeatedcv",
                           repeats = 5,
                           search = "random")

testeControl <- trainControl(method = "gaussprPoly")

preProcValues <- c("center", "scale", "nzv")

```

(i) O modelo de regressão Ridge

```{r}
model.ridge <- train(votos ~ ., 
               data = train,
               trControl = fitControl,
               method = "ridge",
               preProcess = preProcValues,
               tuneLength = 5)
model.ridge
```

(ii) O modelo de regressão Lasso

```{r}
model.lasso <- train(votos ~ .,
                     data = train,
                     trControl = fitControl,
                     method = "lasso",
                     preProcess = preProcValues,
                     tuneLength = 5)
model.lasso
```

(iii) O modelo KNN

```{r}

model.knn <- train(votos ~ .,
                   data = train,
                   method = "knn",
                   preProcess = preProcValues,
                   tuneLength = 5)
model.knn
```

**2. Compare os três modelos em termos do erro RMSE de validação cruzada.**

  Utilizando validação cruzada, temos os seguintes resultados: no modelo de regressão Ridge, o menor RMSE é 34107.36 quando lambda = 0.00104874; o modelo Lasso possui menor RSME igual a 34168.80 quando a fração é 0.4495589; o modelo KNN possui RMSE igual a 34395.36 quando possui número de vizinhos é k = 13.


**3. Quais as variáveis mais importantes segundo o modelo de regressão Ridge e Lasso?  Variáveis foram descartadas pelo Lasso? Quais?**

```{r}
ggplot(varImp(model.ridge))
```
```{r}
ggplot(varImp(model.lasso))
```

